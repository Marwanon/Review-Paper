# Review-Paper
# marwan

ABSTRACT 
The motivation behind our work is to review and analyze 
the most relevant studies on deep reinforcement learning-based object manipulation. 
Various studies are examined through a survey of existing 
literature and investigation of various aspects, namely, 
the intended applications, techniques applied, 
challenges faced by researchers and recommendations 
for minimizing obstacles. 
This review refers to all relevant articles on deep 
reinforcement learning-based object manipulation
and solutions. The object grasping issue is a major
manipulation challenge. Object grasping requires 
detection systems, methods and tools to facilitate 
efficient and fast agent training. Several studies 
have proposed that object grasping and its subtypes 
are the main elements in dealing with the environment 
and agent. Unlike other review articles, this review 
article provides different observations on deep 
reinforcement learning-based manipulation. The results 
of this comprehensive review of deep reinforcement 
learning in the manipulation field may be valuable
for researchers and practitioners because they 
can expedite the establishment of important guidelines.


This paper begins by introducing the study 
and describing related review papers. 
Section II explains the review protocol. 
Section III describes grasping in clutter. 
Sim-to-real transfer is presented 
in Section IV, and learning from demonstration (LfD) 
and well-labelled data are highlighted 
in Sections V and VI, respectively. 
The next two sections present vision-based 
robotic grasping and other applications of deep-RL. 
The limitations of this work and future 
research directions are explained in Section IX.
The last section concludes this work.


Title: Review of Deep Reinforcement Learning-based Object 
Grasping: Techniques, Open Challenges and
Recommendations


1.	Introduction
2.	Review Protocol
    2.1	Selection of Study.
    2.2	Search.
    2.3	Eligibility Criteria.
3.	Grasping In a Cluttered Environment
    3.1	Grasping 
    3.2	Suction and Multifunctional Grasping  
    3.3	Prehensile and Nonprehensile Actions
    3.4	Summary 
4.	Simulation-To-Real-World Transfer
5.	Robots Learning From Demonstration
6.	Well-Labelled Data 
7.	Vision-Based Robotic Grasp
8.	Application of Deep-RL in Various Areas
    8.1	Humanoid Robots
    8.2	High-Precision Assembly Tasks
    8.3	Manipulating Liquids 
9.	Challenges and Future Directions 
    9.1	Challenge of Collision Avoidance
    9.2	Challenge of Selecting Suitable Deep-RL Methods
    9.3	Challenge of Collecting Efficient Data
    9.4	Challenge of Learning from Demonstration 
    9.5	Challenge of Efficient Deep-RL Algorithm
   9.6	Challenge of Synergising Two Actions
10.	Conclusion 
